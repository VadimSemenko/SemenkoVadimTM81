{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Install and Imports"},{"metadata":{"trusted":true},"cell_type":"code","source":"isNeedInstall = False\nif isNeedInstall:\n    import subprocess\n    import sys\n\n    def install(package):\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n\n    install(\"pyspark\")\n    install(\"psutil\")\n    install(\"nbconvert\")\n    install(\"ipykernel\")\n    install(\"py4j\")","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pyspark import SparkConf, SparkContext\nimport os\nimport shutil","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Change to True to run the program on full dataset\nisProd = False","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"number_cores = 2\nmemory_gb = 4\n# Create a configuration object and\n# set the name of the application\nconf = (\n    SparkConf()\n        .setAppName(\"SparkTask\")\n        .setMaster('local[{}]'.format(number_cores))\n        .set('spark.driver.memory', '{}g'.format(memory_gb))\n)\n# Create a Spark Context object\nsc = SparkContext.getOrCreate()#(conf=conf)","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Solution"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the input file\nif isProd:\n    if not os.path.exists('input/Reviews.csv'):\n        sc.stop()\n        raise Exception(\"\"\"\n            Download the 'Reviews.csv' file from https://www.kaggle.com/datasets/snap/amazon-fine-food-reviews\n            and put it in 'input' folder\n        \"\"\")\n    else:\n        inputRdd = sc.textFile(\"input/Reviews.csv\")\nelse:\n    inputRdd = sc.textFile(\"input/Sample.csv\")","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove the header\nfilteredInput = inputRdd.filter(lambda line: line.startswith(\"Id,\") == False)","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. З вхідного датасету створити RDD, що містить пару (tuple) UserId та список всіх ProductId для всіх продуктів, які купував/ревьюва цей юзер. В списку повинні бути лише унікальні продукти (ProductId  для одного юзера не повинні повторюватись). Наприклад:\n(\"A1\", [\"B1\", \"B2\", \"B5\"])\n(\"A2\", [\"B1\", \"B3\", \"B5\"])"},{"metadata":{"trusted":true},"cell_type":"code","source":"userProductMap = filteredInput.map(lambda x: x.split(\",\")[2] + \",\" + x.split(\",\")[1]).map(lambda x: x.split(\",\"))\nuserProductMap.collect()","execution_count":7,"outputs":[{"data":{"text/plain":"[['A2', 'B1'],\n ['A4', 'B1'],\n ['A5', 'B1'],\n ['A1', 'B2'],\n ['A2', 'B3'],\n ['A3', 'B3'],\n ['A4', 'B3'],\n ['A5', 'B3'],\n ['A4', 'B4'],\n ['A2', 'B5'],\n ['A4', 'B5'],\n ['A2', 'B1'],\n ['A4', 'B5'],\n ['A5', 'B5']]"},"execution_count":7,"metadata":{},"output_type":"execute_result"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"zero_value = set()\n\ndef seq_op(x,y):\n    x.add(y)\n    return x\n\ndef comb_op(x,y):\n    return x.union(y)\n\nuserProducts = userProductMap.aggregateByKey(zero_value, seq_op, comb_op).sortByKey()\nuserProducts.collect()","execution_count":8,"outputs":[{"data":{"text/plain":"[('A1', {'B2'}),\n ('A2', {'B1', 'B3', 'B5'}),\n ('A3', {'B3'}),\n ('A4', {'B1', 'B3', 'B4', 'B5'}),\n ('A5', {'B1', 'B3', 'B5'})]"},"execution_count":8,"metadata":{},"output_type":"execute_result"}]},{"metadata":{},"cell_type":"markdown","source":"2. Маючи списки продуктів для кожного юзера, отримати всі пари продуктів які він міг купувати разом. Для кожної такої пари створити tuple де першим елементом є пара, другим число 1. Наприклад для попереднього списку:\n(\"B1,B2\", 1)\n(\"B1,B5\", 1)\n(\"B2,B5\", 1)\n(\"B1,B3\", 1)\n(\"B1,B5\", 1)\n(\"B3,B5\", 1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"productPairsMap = list(userProducts.reduceByKey(lambda a,b: b.lookup(a)).map(lambda r: r[1]).filter(lambda x: len(x)>1).collect())\nprint(productPairsMap)","execution_count":9,"outputs":[{"name":"stdout","output_type":"stream","text":"[{'B1', 'B3', 'B5'}, {'B4', 'B1', 'B3', 'B5'}, {'B1', 'B3', 'B5'}]\n"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"i = 0\nj = 0 \ntupleProduct = []\ntempList = []\nfor x in productPairsMap:\n    tempList.append(list(x))\nwhile i < len(tempList):\n    while j<len(tempList[i])-1:\n        tupleProduct.append(tempList[i][j]+tempList[i][j+1])\n        j+=1\n    i+=1\n    j=0\nprint(tupleProduct)","execution_count":10,"outputs":[{"name":"stdout","output_type":"stream","text":"['B1B3', 'B3B5', 'B4B1', 'B1B3', 'B3B5', 'B1B3', 'B3B5']\n"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"nextStep = sc.parallelize(tupleProduct)\ntupleProductWithOne = nextStep.map(lambda x: (x,1))\ntupleProductWithOne.collect()","execution_count":11,"outputs":[{"data":{"text/plain":"[('B1B3', 1),\n ('B3B5', 1),\n ('B4B1', 1),\n ('B1B3', 1),\n ('B3B5', 1),\n ('B1B3', 1),\n ('B3B5', 1)]"},"execution_count":11,"metadata":{},"output_type":"execute_result"}]},{"metadata":{},"cell_type":"markdown","source":"3. Підрахувати кількість всіх пар продуктів, відсортувати їх за кількістю."},{"metadata":{"trusted":true},"cell_type":"code","source":"allTupleProd = list(tupleProductWithOne.countByKey().items())\ntempProd = sc.parallelize(allTupleProd)\nproductPairsCounts = tempProd.sortBy(lambda x: -x[1])\nproductPairsCounts.collect()","execution_count":12,"outputs":[{"data":{"text/plain":"[('B1B3', 3), ('B3B5', 3), ('B4B1', 1)]"},"execution_count":12,"metadata":{},"output_type":"execute_result"}]},{"metadata":{},"cell_type":"markdown","source":"4. Взяти лише перші 10 пар продуктів та їх кількість. Зберегти в файл. Наприклад:\n(\"B1,B5\", 23495)\n(\"B2,B5\", 3340)\n(\"B3,B5\", 217)"},{"metadata":{"trusted":true},"cell_type":"code","source":"result = productPairsCounts.zipWithIndex().filter(lambda vi: vi[1] < 10).keys()\nresult.collect()","execution_count":13,"outputs":[{"data":{"text/plain":"[('B1B3', 3), ('B3B5', 3), ('B4B1', 1)]"},"execution_count":13,"metadata":{},"output_type":"execute_result"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"outpath = 'output/first_output'\nif os.path.exists(outpath) and os.path.isdir(outpath):\n    shutil.rmtree(outpath)\n\nresult.saveAsTextFile(outpath)","execution_count":14,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Stop the Spark Context"},{"metadata":{"trusted":true},"cell_type":"code","source":"sc.stop()","execution_count":15,"outputs":[]}],"metadata":{"interpreter":{"hash":"98150487c3ea4eb7b8eab087c675bf955334d0813044dccb8841940644ac4c2f"},"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}